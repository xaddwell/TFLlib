# <img src="docs/images/logo1.png" alt="icon" height="50" width="100" style="vertical-align:sub;"/> TFLlib: Trustworthy Federated Learning Library and Benchmark
![Apache License 2.0](https://img.shields.io/badge/license-Apache%202.0-blue.svg)
---

ğŸ¯**If you find our repository useful, please cite the corresponding paper (Coming Soon) and Repository:**

TFLlib is a comprehensive library for trustworthy federated learning research based on [PFLlib](https://github.com/TsingZ0/PFLlib.git). It provides a unified framework to evaluate federated learning algorithms under various trustworthiness threats including Backdoor attacks, Byzantine attacks, Membership Inference Attacks (MIA), Label Inference Attacks (LIA) and Gradient Inversion Attacks (GIA).

![Framework](./docs/images/framework.png)

## Key Features

### Comprehensive FL Algorithms Support
- **Classic FL Algorithms**: FedAvg, FedProx, MOON, SCAFFOLD, FedDyn, FedNTD, FedGen
- **Extensible Architecture**: Easy to implement and integrate new FL algorithms

### Diverse Dataset Support
- **Computer Vision**: CIFAR-10, CIFAR-100, TinyImageNet, FEMNIST
- **Natural Language Processing**: IMDB, AGNews, Sent140
- **Tabular Data**: Adult, Heart, Credit Card, Texas100, Purchase100
- **Time Series**: UCI-HAR
- **Various Data Distribution Settings**: IID, Non-IID (Dirichlet, Pathological, etc.)

### Rich Model Zoo
- **CNN Models**: LeNet, SimpleCNN, ResNet series, VGG, MobileNet, ShuffleNet
- **NLP Models**: LSTM, BERT variants, ALBERT, ELECTRA, MobileBERT, MiniLM, TinyBERT
- **Other Models**: Logistic Regression, HAR-CNN, DeepSpeech

### Security Threats & Attacks

#### Poisoning Attacks
- **Backdoor Attacks**: [DBA](), [A3FL](), [CerP](), [EdgeCase](), [Neurotoxin](), [Replace]()
- **Byzantine Attacks**: [LIE](), [Fang](), [IPM](), [Label Flip](), [Median]() [Tailored](), [Min-Max](), [Noise](), [Sign Flip](), [SignGuard](), [Update Flip]()

#### Privacy Attacks
- **Membership Inference Attacks**: Nasr, Shokri, Zari, ML-Leaks
- **Label Inference Attacks**: Various LIA methods
- **Gradient Inversion Attacks**: DLG, Invert Gradients, See Through Gradients, LOKI, RobFed

### Defense Mechanisms
- **Robust Aggregation**: Krum, Bulyan, Coordinate-wise Median/Trimmed Mean, Geometric Median
- **Detection-Based**: Outlier Detection, Norm Difference Clipping, Cross-Round Defense
- **Others**: Soteria, Weak Differential Privacy, Robust Learning Rate, Foolsgold

### Real-world Simulation
- **System Heterogeneity**: Simulate varying computation capabilities of devices
- **Communication Heterogeneity**: Model unstable network conditions
- **Device Availability**: Handle dynamic client availability

### Multi-GPU Support
- Efficiently utilize multiple GPUs for large-scale federated learning simulations
- Accelerate both training and evaluation processes

## Architecture

```
TFLlib/
â”œâ”€â”€ flcore/
â”‚   â”œâ”€â”€ clients/              # Client-side implementations
â”‚   â”œâ”€â”€ fedatasets/           # Federated datasets
â”‚   â”‚   â”œâ”€â”€ other/            # Various dataset implementations
â”‚   â”‚   â””â”€â”€ utils/            # Dataset utilities
â”‚   â”œâ”€â”€ models/               # Model architectures
â”‚   â”œâ”€â”€ optimizers/           # Federated optimizers
â”‚   â”œâ”€â”€ security/             # Security components
â”‚   â”‚   â”œâ”€â”€ attack/           # Various attack implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ poison/       # Poisoning attacks
â”‚   â”‚   â”‚   â””â”€â”€ privacy/      # Privacy attacks
â”‚   â”‚   â””â”€â”€ defense/          # Defense mechanisms
â”‚   â”œâ”€â”€ servers/              # Server-side implementations
â”‚   â”œâ”€â”€ simulation/           # Real-world simulation modules
â”‚   â””â”€â”€ utils/                # Utility functions
â”œâ”€â”€ main.py                   # Main entry point
â”œâ”€â”€ run_exp_*.py              # Experiment scripts
â””â”€â”€ config.py                 # Configuration parsing
```


## ToDo List

- â­•ï¸ Add the parameter configurations for each experiment script
- â­•ï¸ Provide .toml configuration files for easy experiment reproduction
- â­•ï¸ Polish the documentation and add more tutorials
- â­•ï¸ Provide datasets and pretrained models download scripts
- â­•ï¸ Add more defense mechanisms

## Getting Started [TODO]

### Installation

```bash
# Clone the repository
git clone https://github.com/xaddwell/TFLlib.git
cd TFLlib

# Install dependencies
pip install -r requirements.txt
```

### Basic Usage

Run federated learning experiments with various configurations:

```bash
# Basic FedAvg on CIFAR-10
python main.py --algorithm FedAvg --data_name CIFAR10 --model_name resnet18

# Run with non-IID data setting
python main.py --algorithm FedAvg --data_name CIFAR10 --model_name resnet18 --split_type diri --cncntrtn 0.5

# Run with system heterogeneity simulation
python main.py --algorithm FedAvg --data_name CIFAR10 --model_name resnet18 --dev_hetero 0.5 --comm_hetero 0.5
```

### Pre-configured Experiments

We provide several experiment scripts for reproducing results:

```bash
# Backdoor attack experiments
python run_exp_backdoor.py

# Byzantine attack experiments
python run_exp_byzantine.py

# Privacy attack experiments
python run_exp_inversion.py
python run_exp_lia.py
```

### Key Parameters for FL Training

| Parameter | Description | Default |
|----------|-------------|---------|
| `--algorithm` | FL algorithm to use | FedAvg |
| `--data_name` | Dataset to use | CIFAR10 |
| `--model_name` | Model architecture | resnet18 |
| `--num_clients` | Total number of clients | 100 |
| `--join_ratio` | Fraction of clients participating in each round | 0.1 |
| `--local_epochs` | Number of local training epochs | 2 |
| `--global_rounds` | Number of global communication rounds | 500 |
| `--split_type` | Data distribution type | iid |
| `--dev_hetero` | Device heterogeneity level (0-1) | 0.5 |
| `--comm_hetero` | Communication heterogeneity level (0-1) | 0.5 |


### Key Parameters for Client Attack [TODO]
Coming soon...


### Key Parameters for Server Attack [TODO]
Coming soon...


## Real-world Environment Simulation

TFLlib provides realistic simulation capabilities:

1. **Device Heterogeneity**: Clients have different computational capabilities
2. **Communication Heterogeneity**: Network conditions vary among clients
3. **Client Availability**: Dynamic client participation patterns

These features enable researchers to evaluate FL algorithms under practical deployment conditions.

## Multi-GPU Training
Coming soon...

## Extending TFLlib with you own Attack & Defense Mechanisms [TODO]
Coming soon...


## Citation

If you use TFLlib in your research, please cite our repo:

```bibtex
@misc{chen2025tfllib,
  title={TFLlib: Trustworthy Federated Learning Library and Benchmark},
  author={Jiahao Chen, Zhiming Zhao and Jianqing Zhang},
  year={2025},
  url={https://github.com/xaddwell/TFLlib}
}
```

## License

This project is licensed under the Apache License - see the [LICENSE](./LICENSE) file for details.

## Acknowledgments
We thank all the researchers who contribute to the development of TFLlib. Especially, we thank the benchmark [PFLlib](https://github.com/TsingZ0/PFLlib.git), provided by [Jianqing Zhang](https://github.com/TsingZ0).